{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrsaBb_2XEfr",
        "outputId": "fc11d3d0-e0b2-4f11-e45f-d5fd184e022e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scanpy anndata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAHuBA7Ma0mn",
        "outputId": "347e19ad-5200-4e5c-9721-311c091aa16e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scanpy in /usr/local/lib/python3.10/dist-packages (1.9.6)\n",
            "Requirement already satisfied: anndata in /usr/local/lib/python3.10/dist-packages (0.10.3)\n",
            "Requirement already satisfied: h5py>=3 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.9.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.3.2)\n",
            "Requirement already satisfied: matplotlib>=3.4 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.7.1)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy) (8.4.0)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.2.1)\n",
            "Requirement already satisfied: numba>=0.41.0 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.58.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from scanpy) (23.2)\n",
            "Requirement already satisfied: pandas!=2.1.2,>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.5.3)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.11.3)\n",
            "Requirement already satisfied: seaborn!=0.13.0 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.12.2)\n",
            "Requirement already satisfied: session-info in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.0.0)\n",
            "Requirement already satisfied: statsmodels>=0.10.0rc2 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from scanpy) (4.66.1)\n",
            "Requirement already satisfied: umap-learn>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.5.5)\n",
            "Requirement already satisfied: array-api-compat in /usr/local/lib/python3.10/dist-packages (from anndata) (1.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata) (1.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.41.0->scanpy) (0.41.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.2,>=1.1.1->scanpy) (2023.3.post1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->scanpy) (3.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy->scanpy) (1.16.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.3.10->scanpy) (0.5.11)\n",
            "Requirement already satisfied: stdlib-list in /usr/local/lib/python3.10/dist-packages (from session-info->scanpy) (0.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scanpy as sc\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "q1S9pzO1a2uz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preview(adata):\n",
        "    print(\"\\nUns:\", adata.uns)\n",
        "    print(\"Observations:\", adata.obs.head())\n",
        "    print(\"\\nVariables:\", adata.var.head())\n",
        "    print(\"Shape:\", adata.shape)"
      ],
      "metadata": {
        "id": "-FpTt5-3gTUZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_subsample(file_path, n_obs):\n",
        "    adata = sc.read(file_path)\n",
        "    sc.pp.subsample(adata, n_obs=n_obs, random_state=42)\n",
        "    return adata\n",
        "\n",
        "def generate_sample_dataset():\n",
        "    base_path = '/content/drive/MyDrive/modality prediction/GEX2ATAC/'\n",
        "    datasets = ['train_mod1', 'train_mod2']\n",
        "    n_obs = 5000\n",
        "\n",
        "    for dataset in datasets:\n",
        "        file_path = base_path + f'{dataset}.h5ad'\n",
        "        sampled_file_path = f'/content/drive/MyDrive/modality prediction/GEX2ATAC/sampled_{dataset}.h5ad'\n",
        "\n",
        "        loaded_data = load_and_subsample(file_path, n_obs)\n",
        "        loaded_data.write(sampled_file_path)\n"
      ],
      "metadata": {
        "id": "LY57jw9EcGoC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_data_generation(adata_mod1_train_sample, adata_mod2_train_sample, adata_mod1_test_sample, adata_mod2_test_sample):\n",
        "  # extract data matrices for training and testing\n",
        "  train_X = adata_mod1_train_sample.X\n",
        "  train_y = adata_mod2_train_sample.X\n",
        "  test_X = adata_mod1_test_sample.X\n",
        "  test_y = adata_mod2_test_sample.X\n",
        "\n",
        "  # convert to dense\n",
        "  train_X = train_X.toarray()\n",
        "  train_y = train_y.toarray()\n",
        "  test_X = test_X.toarray()\n",
        "  test_y = test_y.toarray()\n",
        "  return train_X, train_y, test_X, test_y"
      ],
      "metadata": {
        "id": "LhGFUk51bdIV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RMSE(test_y, predictions):\n",
        "  # evaluate the model on the original testing data\n",
        "  rmse = mean_squared_error(test_y, predictions, squared=False)\n",
        "  print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')"
      ],
      "metadata": {
        "id": "q1YosTy1cGGQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_regression(train_X, train_y, test_X, test_y):\n",
        "  # train a linear regression model\n",
        "  model = LinearRegression()\n",
        "  model.fit(train_X, train_y)\n",
        "  predictions = model.predict(test_X)\n",
        "\n",
        "  # evaluate the model\n",
        "  RMSE(test_y, predictions)"
      ],
      "metadata": {
        "id": "0gh7H-rvODJ9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SVD_linear_regression(train_X, train_y, test_X, test_y):\n",
        "  # perform SVD on the training data\n",
        "  num_components = 50\n",
        "  svd_X = TruncatedSVD(n_components=num_components)\n",
        "  svd_y = TruncatedSVD(n_components=num_components)\n",
        "  lsi_matrix_train_X = svd_X.fit_transform(train_X)\n",
        "  lsi_matrix_train_y = svd_y.fit_transform(train_y)\n",
        "\n",
        "  # train a linear regression model\n",
        "  model = LinearRegression()\n",
        "  model.fit(lsi_matrix_train_X, lsi_matrix_train_y)\n",
        "\n",
        "  # transform the testing data using the same SVD transformation\n",
        "  lsi_matrix_test_X = svd_X.transform(test_X)\n",
        "\n",
        "  # make predictions on the testing data\n",
        "  lsi_predictions_y = model.predict(lsi_matrix_test_X)\n",
        "  predictions = svd_y.inverse_transform(lsi_predictions_y)\n",
        "\n",
        "  # evaluate the model\n",
        "  RMSE(test_y, predictions)"
      ],
      "metadata": {
        "id": "Da-KOqzJcUOB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TFIDF_linear_regression(train_X, train_y, test_X, test_y):\n",
        "  # apply TF-IDF to training and testing data\n",
        "  tfidf_transformer_X = TfidfTransformer()\n",
        "  tfidf_transformer_y = TfidfTransformer()\n",
        "  tfidf_train_X = tfidf_transformer_X.fit_transform(train_X)\n",
        "  tfidf_train_y = tfidf_transformer_y.fit_transform(train_y)\n",
        "\n",
        "\n",
        "  # perform SVD on the training data\n",
        "  num_components = 50\n",
        "  svd_X = TruncatedSVD(n_components=num_components)\n",
        "  svd_y = TruncatedSVD(n_components=num_components)\n",
        "  lsi_matrix_train_X = svd_X.fit_transform(tfidf_train_X)\n",
        "  lsi_matrix_train_y = svd_y.fit_transform(tfidf_train_y)\n",
        "\n",
        "\n",
        "  # train a linear regression model\n",
        "  model = LinearRegression()\n",
        "  model.fit(lsi_matrix_train_X, lsi_matrix_train_y)\n",
        "\n",
        "  # transform the testing data using the same TFIDF vectorizer and SVD transformation\n",
        "  tfidf_test_X = tfidf_transformer_X.transform(test_X)\n",
        "  lsi_matrix_test_X = svd_X.transform(tfidf_test_X)\n",
        "  predictions = model.predict(lsi_matrix_test_X)\n",
        "\n",
        "  # inverse transform\n",
        "  inverse_svd_predictions = svd_y.inverse_transform(predictions)\n",
        "  inverse_tfidf_predictions = inverse_svd_predictions * (1 / tfidf_transformer_y.idf_)\n",
        "\n",
        "  # evaluate the model\n",
        "  RMSE(test_y, inverse_tfidf_predictions)"
      ],
      "metadata": {
        "id": "O9-a1YL9d2Fz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define autoencoder model\n",
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, input_dim, encoding_dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "      nn.Linear(input_dim, encoding_dim),\n",
        "      nn.ReLU()\n",
        "      )\n",
        "    self.decoder = nn.Sequential(\n",
        "      nn.Linear(encoding_dim, input_dim),\n",
        "      nn.Sigmoid()\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "def autoencoder_linear_regression(train_X, train_y, test_X, test_y):\n",
        "  # train the autoencoder\n",
        "  input_dim = train_X.shape[1]\n",
        "  encoding_dim = 50\n",
        "  autoencoder = Autoencoder(input_dim, encoding_dim)\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = optim.Adam(autoencoder.parameters(), lr=0.01)\n",
        "  num_epochs = 10\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    inputs = torch.FloatTensor(train_X)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = autoencoder(inputs)\n",
        "    loss = criterion(outputs, inputs)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "  # encode the training and testing data using the autoencoder\n",
        "  autoencoder.eval()\n",
        "  encoded_train_X = autoencoder.encoder(torch.FloatTensor(train_X)).detach().numpy()\n",
        "  encoded_test_X = autoencoder.encoder(torch.FloatTensor(test_X)).detach().numpy()\n",
        "\n",
        "  # train a linear regression model\n",
        "  linear_regression(encoded_train_X, train_y, encoded_test_X, test_y)\n",
        "\n",
        "\n",
        "def autoencoder_SVD_linear_regression(train_X, train_y, test_X, test_y):\n",
        "  # get SVD\n",
        "  num_components = 50\n",
        "  svd_X = TruncatedSVD(n_components=num_components)\n",
        "  svd_y = TruncatedSVD(n_components=num_components)\n",
        "  lsi_matrix_train_X = svd_X.fit_transform(train_X)\n",
        "  lsi_matrix_train_y = svd_y.fit_transform(train_y)\n",
        "  lsi_matrix_test_X = svd_y.transform(test_y)\n",
        "\n",
        "  # train the autoencoder\n",
        "  input_dim = lsi_matrix_train_X.shape[1]\n",
        "  encoding_dim = 50\n",
        "  autoencoder = Autoencoder(input_dim, encoding_dim)\n",
        "  criterion = nn.MSELoss()\n",
        "  optimizer = optim.Adam(autoencoder.parameters(), lr=0.01)\n",
        "  num_epochs = 10\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    inputs = torch.FloatTensor(lsi_matrix_train_X)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = autoencoder(inputs)\n",
        "    loss = criterion(outputs, inputs)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "  # encode the training and testing data using the autoencoder\n",
        "  autoencoder.eval()\n",
        "  encoded_train_X = autoencoder.encoder(torch.FloatTensor(lsi_matrix_train_X)).detach().numpy()\n",
        "  encoded_test_X = autoencoder.encoder(torch.FloatTensor(lsi_matrix_test_X)).detach().numpy()\n",
        "\n",
        "  # train a linear regression model\n",
        "  model = LinearRegression()\n",
        "  model.fit(encoded_train_X, lsi_matrix_train_y)\n",
        "\n",
        "  # make predictions on the testing data\n",
        "  lsi_predictions_y = model.predict(encoded_test_X)\n",
        "  predictions = svd_y.inverse_transform(lsi_predictions_y)\n",
        "\n",
        "  # evaluate the model\n",
        "  RMSE(test_y, predictions)"
      ],
      "metadata": {
        "id": "0-lRSOWr8l42"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  # load the original training file\n",
        "  file_path = '/content/drive/MyDrive/modality prediction/GEX2ATAC/train_mod1.h5ad'\n",
        "  adata = sc.read(file_path)\n",
        "\n",
        "  # preview basic information\n",
        "  preview(adata)\n",
        "\n",
        "  # generate sample dataset\n",
        "  generate_sample_dataset()\n",
        "\n",
        "  # read the sample dataset\n",
        "  mod1_train_sample = sc.read('/content/drive/MyDrive/modality prediction/GEX2ATAC/sampled_train_mod1.h5ad')\n",
        "  mod2_train_sample = sc.read('/content/drive/MyDrive/modality prediction/GEX2ATAC/sampled_train_mod2.h5ad')\n",
        "  mod1_test_sample = sc.read('/content/drive/MyDrive/modality prediction/GEX2ATAC/test_mod1.h5ad')\n",
        "  mod2_test_sample = sc.read('/content/drive/MyDrive/modality prediction/GEX2ATAC/test_mod2.h5ad')\n",
        "  print('mod1_train shape:', mod1_train_sample.shape)\n",
        "  print('mod2_train shape:', mod2_train_sample.shape)\n",
        "\n",
        "  # convert sparse matrices to df for better handling\n",
        "  train_X, train_y, test_X, test_y = dense_data_generation(mod1_train_sample, mod2_train_sample, mod1_test_sample, mod2_test_sample)\n",
        "  device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "  # GEX2ATAC\n",
        "  print(\"For GEX to ATAC using linear regression only\")\n",
        "  linear_regression(train_X, train_y, test_X, test_y)\n",
        "  print(\"For GEX to ATAC using SVD\")\n",
        "  SVD_linear_regression(train_X, train_y, test_X, test_y)\n",
        "  print(\"For GEX to ATAC using TFIDF\")\n",
        "  TFIDF_linear_regression(train_X, train_y, test_X, test_y)\n",
        "  print(\"For GEX to ATAC using autoencoder\")\n",
        "  autoencoder_linear_regression(train_X, train_y, test_X, test_y)\n",
        "  print(\"For GEX to ATAC using SVD and autoencoder\")\n",
        "  autoencoder_SVD_linear_regression(train_X, train_y, test_X, test_y)\n",
        "\n",
        "  # ATAC2GEX\n",
        "  print(\"For ATAC to GEX using linear regression only\")\n",
        "  linear_regression(train_y, train_X, test_y, test_X)\n",
        "  print(\"For ATAC to GEX using SVD\")\n",
        "  SVD_linear_regression(train_y, train_X, test_y, test_X)\n",
        "  print(\"For ATAC to GEX using TFIDF\")\n",
        "  TFIDF_linear_regression(train_y, train_X, test_y, test_X)\n",
        "  print(\"For ATAC to GEX using autoencoder\")\n",
        "  autoencoder_linear_regression(train_y, train_X, test_y, test_X)\n",
        "  print(\"For ATAC to GEX using SVD and autoencoder\")\n",
        "  autoencoder_SVD_linear_regression(train_y, train_X, test_y, test_X)"
      ],
      "metadata": {
        "id": "Y8RZ0H7hhm9_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COTRcVU2hojC",
        "outputId": "836fdb33-9bcf-4aa7-91bf-493593fe52f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Uns: {'dataset_id': 'openproblems_bmmc_multiome_phase1v2_PM_gex2atac', 'organism': 'human'}\n",
            "Observations:                         batch  size_factors\n",
            "TAGTTGTCACCCTCAC-1-s1d1  s1d1      0.453484\n",
            "CTATGGCCATAACGGG-1-s1d1  s1d1      0.455631\n",
            "CCGCACACAGGTTAAA-1-s1d1  s1d1      2.435348\n",
            "TCATTTGGTAATGGAA-1-s1d1  s1d1      0.347226\n",
            "ACCACATAGGTGTCCA-1-s1d1  s1d1      0.534205\n",
            "\n",
            "Variables:                    gene_ids feature_types\n",
            "AL627309.5  ENSG00000241860           GEX\n",
            "LINC01409   ENSG00000237491           GEX\n",
            "LINC01128   ENSG00000228794           GEX\n",
            "NOC2L       ENSG00000188976           GEX\n",
            "KLHL17      ENSG00000187961           GEX\n",
            "Shape: (30329, 13431)\n",
            "mod1_train shape: (5000, 13431)\n",
            "mod2_train shape: (5000, 10000)\n",
            "For GEX to ATAC using linear regression only\n",
            "Root Mean Squared Error (RMSE): 0.1909\n",
            "For GEX to ATAC using SVD\n",
            "Root Mean Squared Error (RMSE): 0.1385\n",
            "For GEX to ATAC using TFIDF\n",
            "Root Mean Squared Error (RMSE): 0.1443\n",
            "For GEX to ATAC using autoencoder\n",
            "Epoch 1/10, Loss: 0.2873266637325287\n",
            "Epoch 2/10, Loss: 0.32323670387268066\n",
            "Epoch 3/10, Loss: 0.2631716728210449\n",
            "Epoch 4/10, Loss: 0.20174247026443481\n",
            "Epoch 5/10, Loss: 0.17425228655338287\n",
            "Epoch 6/10, Loss: 0.1491246372461319\n",
            "Epoch 7/10, Loss: 0.13044853508472443\n",
            "Epoch 8/10, Loss: 0.1197303831577301\n",
            "Epoch 9/10, Loss: 0.11439809948205948\n",
            "Epoch 10/10, Loss: 0.11228940635919571\n",
            "Root Mean Squared Error (RMSE): 0.1390\n",
            "For GEX to ATAC using SVD and autoencoder\n",
            "Epoch 1/10, Loss: 15.982890129089355\n",
            "Epoch 2/10, Loss: 15.715063095092773\n",
            "Epoch 3/10, Loss: 15.437372207641602\n",
            "Epoch 4/10, Loss: 15.178709983825684\n",
            "Epoch 5/10, Loss: 14.974114418029785\n",
            "Epoch 6/10, Loss: 14.833335876464844\n",
            "Epoch 7/10, Loss: 14.742170333862305\n",
            "Epoch 8/10, Loss: 14.682913780212402\n",
            "Epoch 9/10, Loss: 14.641960144042969\n",
            "Epoch 10/10, Loss: 14.610391616821289\n",
            "Root Mean Squared Error (RMSE): 0.1395\n",
            "For ATAC to GEX using linear regression only\n",
            "Root Mean Squared Error (RMSE): 0.6185\n",
            "For ATAC to GEX using SVD\n",
            "Root Mean Squared Error (RMSE): 0.2248\n",
            "For ATAC to GEX using TFIDF\n",
            "Root Mean Squared Error (RMSE): 0.2526\n",
            "For ATAC to GEX using autoencoder\n",
            "Epoch 1/10, Loss: 0.2506161332130432\n",
            "Epoch 2/10, Loss: 0.2059493362903595\n",
            "Epoch 3/10, Loss: 0.15081794559955597\n",
            "Epoch 4/10, Loss: 0.09628807753324509\n",
            "Epoch 5/10, Loss: 0.060259900987148285\n",
            "Epoch 6/10, Loss: 0.04204482585191727\n",
            "Epoch 7/10, Loss: 0.03411819785833359\n",
            "Epoch 8/10, Loss: 0.03080570511519909\n",
            "Epoch 9/10, Loss: 0.029406502842903137\n",
            "Epoch 10/10, Loss: 0.028633704409003258\n",
            "Root Mean Squared Error (RMSE): 0.2265\n",
            "For ATAC to GEX using SVD and autoencoder\n",
            "Epoch 1/10, Loss: 1.3422638177871704\n",
            "Epoch 2/10, Loss: 1.286853551864624\n",
            "Epoch 3/10, Loss: 1.2353806495666504\n",
            "Epoch 4/10, Loss: 1.1874405145645142\n",
            "Epoch 5/10, Loss: 1.1438616514205933\n",
            "Epoch 6/10, Loss: 1.1059778928756714\n",
            "Epoch 7/10, Loss: 1.0749709606170654\n",
            "Epoch 8/10, Loss: 1.0512081384658813\n",
            "Epoch 9/10, Loss: 1.034059762954712\n",
            "Epoch 10/10, Loss: 1.0221999883651733\n",
            "Root Mean Squared Error (RMSE): 0.3183\n"
          ]
        }
      ]
    }
  ]
}